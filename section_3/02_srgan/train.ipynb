{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRGAN (Super-Resolution Generative Adversarial Network)\n",
    "\n",
    "A tensorflow implementation of \"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\" paper (https://arxiv.org/abs/1609.04802). This implementation is quite different from original paper. The differences are as followings:\n",
    "\n",
    "1. MNIST data set is used for convenience.\n",
    "2. Replaced MSE loss with GAN using tuple input for discriminator.\n",
    "3. Used sub-pixel CNN instead of deconvolution. (see : http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shi_Real-Time_Single_Image_CVPR_2016_paper.pdf)\n",
    "\n",
    "The existing CNN based super-resolution skill mainly use MSE loss and this makes super-resolved images look blurry. If we replace MSE loss with gradients from GAN, we may prevent the blurry artifacts of the super-resolved images and this is the key idea of this paper.\n",
    "\n",
    "#### Credits\n",
    "\n",
    "Credits for this code goes to https://github.com/buriburisuri/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sugartensor as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set log level to debug\n",
    "tf.sg_verbosity(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./asset/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./asset/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./asset/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./asset/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST input tensor (with QueueRunner)\n",
    "data = tf.sg_data.Mnist(batch_size=batch_size)\n",
    "\n",
    "# input images\n",
    "x = data.train.image\n",
    "\n",
    "# low resolution image\n",
    "x_small = tf.image.resize_bicubic(x, (14, 14))\n",
    "x_nearest = tf.image.resize_images(x_small, (28, 28), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "# generator labels (all ones)\n",
    "y = tf.ones(batch_size, dtype=tf.sg_floatx)\n",
    "\n",
    "# discriminator labels (half 1s, half 0s)\n",
    "y_disc = tf.concat([y, y * 0], 0, name='concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator network\n",
    "with tf.sg_context(name='generator', act='relu', bn=True):\n",
    "    gen = (x_small\n",
    "           .sg_conv(dim=32)\n",
    "           .sg_conv()\n",
    "           .sg_conv(dim=4, act='sigmoid', bn=False)\n",
    "           .sg_periodic_shuffle(factor=2))\n",
    "    \n",
    "# add image summary\n",
    "tf.sg_summary_image(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image pairs\n",
    "x_real_pair = tf.concat([x_nearest, x], 3, name='concat')\n",
    "x_fake_pair = tf.concat([x_nearest, gen], 3, name='concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create discriminator & recognizer\n",
    "\n",
    "# create real + fake image input\n",
    "xx = tf.concat([x_real_pair, x_fake_pair], 0, name='concat')\n",
    "\n",
    "with tf.sg_context(name='discriminator', size=4, stride=2, act='leaky_relu'):\n",
    "    # discriminator part\n",
    "    disc = (xx.sg_conv(dim=64)\n",
    "              .sg_conv(dim=128)\n",
    "              .sg_flatten()\n",
    "              .sg_dense(dim=1024)\n",
    "              .sg_dense(dim=1, act='linear')\n",
    "              .sg_squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and train ops\n",
    "loss_disc = tf.reduce_mean(disc.sg_bce(target=y_disc))  # discriminator loss\n",
    "loss_gen = tf.reduce_mean(disc.sg_reuse(input=x_fake_pair).sg_bce(target=y))  # generator loss\n",
    "\n",
    "train_disc = tf.sg_optim(loss_disc, lr=0.0001, category='discriminator')  # discriminator train ops\n",
    "train_gen = tf.sg_optim(loss_gen, lr=0.001, category='generator')  # generator train ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from asset/train/model.ckpt-17385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0325:18:43:55.548:sg_train.py:327] Training started from epoch[010]-step[17385].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  14%|███▍                    | 247/1718 [00:09<00:57, 25.76b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.65219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  18%|████▏                   | 303/1718 [00:19<01:31, 15.52b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 11.2995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  21%|████▉                   | 357/1718 [00:29<01:53, 12.04b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  24%|█████▋                  | 409/1718 [00:39<02:06, 10.35b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  27%|██████▍                 | 461/1718 [00:49<02:15,  9.31b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███████▏                | 511/1718 [00:59<02:20,  8.59b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  33%|███████▊                | 563/1718 [01:09<02:22,  8.10b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  36%|████████▌               | 615/1718 [01:19<02:22,  7.72b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  39%|█████████▎              | 667/1718 [01:29<02:21,  7.44b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.3997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0325:18:48:46.786:sg_train.py:301] \tEpoch[010:gs=20411] - loss = 1.599364\n",
      "I 0325:18:49:26.361:sg_train.py:301] \tEpoch[011:gs=20821] - loss = 1.594539\n",
      "I 0325:18:54:25.047:sg_train.py:301] \tEpoch[012:gs=23847] - loss = 1.687448\n",
      "I 0325:18:55:07.348:sg_train.py:301] \tEpoch[013:gs=24257] - loss = 1.639389\n",
      "I 0325:19:00:36.803:sg_train.py:301] \tEpoch[014:gs=27283] - loss = 1.640004\n",
      "I 0325:19:01:22.037:sg_train.py:301] \tEpoch[015:gs=27693] - loss = 1.704872\n",
      "I 0325:19:06:52.349:sg_train.py:301] \tEpoch[016:gs=30719] - loss = 1.690638\n",
      "I 0325:19:07:37.229:sg_train.py:301] \tEpoch[017:gs=31129] - loss = 1.807905\n",
      "I 0325:19:13:07.412:sg_train.py:301] \tEpoch[018:gs=34155] - loss = 1.869398\n",
      "I 0325:19:13:52.517:sg_train.py:301] \tEpoch[019:gs=34565] - loss = 1.836846\n",
      "I 0325:19:19:28.311:sg_train.py:301] \tEpoch[020:gs=37591] - loss = 1.920649\n",
      "I 0325:19:19:30.469:sg_train.py:368] Training finished at epoch[20]-step[37591].\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "# def alternate training func\n",
    "@tf.sg_train_func\n",
    "def alt_train(sess, opt):\n",
    "    l_disc = sess.run([loss_disc, train_disc])[0]  # training discriminator\n",
    "    l_gen = sess.run([loss_gen, train_gen])[0]  # training generator\n",
    "    return np.mean(l_disc) + np.mean(l_gen)\n",
    "\n",
    "# do training\n",
    "alt_train(log_interval=10, max_ep=20, ep_size=data.train.num_batch, early_stop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
